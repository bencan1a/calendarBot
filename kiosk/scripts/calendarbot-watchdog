#!/usr/bin/env python3
"""
CalendarBot Kiosk Watchdog Service

Pi Zero 2 optimized monitoring and automatic recovery for CalendarBot_Lite.
Implements 4-level escalation: browser restart → X restart → systemd service restart → reboot.

Uses only Python stdlib for minimal resource footprint.
"""

import argparse
import fcntl
import json
import logging
import os
import signal
import subprocess
import sys
import threading
import time
import urllib.error
import urllib.request
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

__version__ = "1.0.0"

# Global state
_shutdown_requested = False
_config: dict[str, Any] = {}
_state_lock = threading.Lock()


class WatchdogState:
    """Persistent state management for rate limiting and recovery tracking."""
    
    def __init__(self, state_file: Path):
        self.state_file = Path(state_file)
        self.state_file.parent.mkdir(parents=True, exist_ok=True)
        self._lock_fd: Optional[int] = None
        
    def _acquire_lock(self, timeout: int = 30) -> bool:
        """Acquire exclusive file lock with timeout."""
        lock_file = self.state_file.with_suffix('.lock')
        try:
            self._lock_fd = os.open(str(lock_file), os.O_CREAT | os.O_WRONLY | os.O_TRUNC)
            # Non-blocking lock attempt with timeout
            start_time = time.time()
            while time.time() - start_time < timeout:
                try:
                    fcntl.flock(self._lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                    return True
                except BlockingIOError:
                    time.sleep(0.1)
            return False
        except OSError:
            return False
    
    def _release_lock(self) -> None:
        """Release file lock."""
        if self._lock_fd is not None:
            try:
                fcntl.flock(self._lock_fd, fcntl.LOCK_UN)
                os.close(self._lock_fd)
            except OSError:
                pass
            finally:
                self._lock_fd = None
    
    def load_state(self) -> dict[str, Any]:
        """Load state from persistent storage."""
        if not self.state_file.exists():
            return {
                'browser_restarts': [],
                'service_restarts': [],
                'reboots': [],
                'last_recovery_time': None,
                'consecutive_failures': 0,
                'degraded_mode': False,
                'browser_escalation_level': 0,
                'browser_escalation_time': None
            }
        
        try:
            with open(self.state_file) as f:
                return json.load(f)
        except (OSError, json.JSONDecodeError) as e:
            logging.warning(f"Failed to load state file: {e}, using defaults")
            return self.load_state()  # Return defaults
    
    def save_state(self, state: dict[str, Any]) -> bool:
        """Save state to persistent storage atomically."""
        if not self._acquire_lock():
            logging.error("Failed to acquire state lock for save")
            return False
        
        try:
            temp_file = self.state_file.with_suffix('.tmp')
            with open(temp_file, 'w') as f:
                json.dump(state, f, indent=2)
            temp_file.replace(self.state_file)
            return True
        except OSError:
            logging.exception("Failed to save state")
            return False
        finally:
            self._release_lock()
    
    def cleanup_old_entries(self, state: dict[str, Any], hours: int = 24) -> None:
        """Remove entries older than specified hours."""
        cutoff = time.time() - (hours * 3600)
        for key in ['browser_restarts', 'service_restarts']:
            if key in state:
                state[key] = [ts for ts in state[key] if ts > cutoff]
        
        # Reboots have 24h cleanup
        if 'reboots' in state:
            state['reboots'] = [ts for ts in state['reboots'] if ts > cutoff]


class StructuredLogger:
    """JSON structured logging for monitoring events."""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def log_event(self, level: str, component: str, event: str,
                  details: Optional[dict[str, Any]] = None,
                  action_taken: bool = False) -> None:
        """Log structured monitoring event."""
        log_entry = {
            'ts': datetime.now(timezone.utc).isoformat(),
            'component': component,
            'level': level,
            'event': event,
            'details': details or {},
            'action_taken': action_taken
        }
        
        log_method = getattr(self.logger, level.lower(), self.logger.info)
        log_method(json.dumps(log_entry))


class SystemDiagnostics:
    """System resource monitoring for graceful degradation."""
    
    @staticmethod
    def get_load_average() -> Optional[float]:
        """Get 1-minute load average."""
        try:
            with open('/proc/loadavg') as f:
                return float(f.read().split()[0])
        except (OSError, ValueError, IndexError):
            return None
    
    @staticmethod
    def get_free_memory_kb() -> Optional[int]:
        """Get available memory in KB."""
        try:
            with open('/proc/meminfo') as f:
                for line in f:
                    if line.startswith('MemAvailable:'):
                        return int(line.split()[1])
        except (OSError, ValueError, IndexError):
            return None
    
    @classmethod
    def should_degrade(cls, config: dict[str, Any]) -> bool:
        """Check if system should operate in degraded mode."""
        limits = config.get('resource_limits', {})
        if not limits.get('auto_throttle', True):
            return False
        
        load = cls.get_load_average()
        if load and load > limits.get('max_load_1m', 1.5):
            return True
        
        mem = cls.get_free_memory_kb()
        return mem is not None and mem < limits.get('min_free_mem_kb', 60000)


class HealthChecker:
    """Health monitoring and failure detection."""
    
    def __init__(self, config: dict[str, Any], logger: StructuredLogger):
        self.config = config
        self.logger = logger
        self.health_config = config.get('health_check', {})
        self.base_url = self.health_config.get('base_url', 'http://127.0.0.1:8080')
        self.timeout = self.health_config.get('request_timeout_s', 6)
        self.render_marker = self.health_config.get('render_marker', 'name="calendarbot-ready"')
    
    def check_health_endpoint(self) -> tuple[bool, Optional[dict[str, Any]]]:
        """Check /api/health endpoint."""
        try:
            url = f"{self.base_url}/api/health"
            req = urllib.request.Request(url)
            req.add_header('User-Agent', f'CalendarBot-Watchdog/{__version__}')
            
            with urllib.request.urlopen(req, timeout=self.timeout) as response:
                if response.status == 200:
                    data = json.loads(response.read().decode())
                    
                    # Check if status is ok and recent refresh
                    status_ok = data.get('status') == 'ok'
                    last_refresh = data.get('last_refresh', {})
                    refresh_delta = last_refresh.get('last_success_delta_s')
                    
                    # Consider degraded if refresh is too old
                    refresh_threshold = self.health_config.get('refresh_miss_factor', 2) * 300  # 10min default
                    if refresh_delta and refresh_delta > refresh_threshold:
                        status_ok = False
                    
                    self.logger.log_event('DEBUG', 'healthcheck', 'health.endpoint.check',
                                        {'status': data.get('status'), 'refresh_delta_s': refresh_delta})
                    
                    return status_ok, data
                self.logger.log_event('WARN', 'healthcheck', 'health.endpoint.http_error',
                                    {'status_code': response.status})
                return False, None
                    
        except (urllib.error.URLError, json.JSONDecodeError, KeyError) as e:
            self.logger.log_event('WARN', 'healthcheck', 'health.endpoint.fail',
                                {'error': str(e)})
            return False, None
    
    def check_render_probe(self) -> bool:
        """Check if HTML page renders properly."""
        try:
            req = urllib.request.Request(self.base_url)
            req.add_header('User-Agent', f'CalendarBot-Watchdog/{__version__}')
            
            with urllib.request.urlopen(req, timeout=self.timeout) as response:
                if response.status == 200:
                    html = response.read().decode('utf-8', errors='ignore')
                    marker_found = self.render_marker in html
                    
                    self.logger.log_event('DEBUG', 'healthcheck', 'render.probe.check',
                                        {'marker_found': marker_found, 'html_length': len(html)})
                    
                    return marker_found
                self.logger.log_event('WARN', 'healthcheck', 'render.probe.http_error',
                                    {'status_code': response.status})
                return False
                    
        except urllib.error.URLError as e:
            self.logger.log_event('WARN', 'healthcheck', 'render.probe.fail',
                                {'error': str(e)})
            return False
    
    def check_browser_process(self) -> bool:
        """Check if browser process is running."""
        try:
            cmd = self.config.get('commands', {}).get('browser_detect_cmd', 'pgrep -f chromium')
            result = subprocess.run(cmd, check=False, shell=True, capture_output=True, timeout=5)
            
            running = result.returncode == 0
            self.logger.log_event('DEBUG', 'healthcheck', 'browser.process.check',
                                {'running': running, 'returncode': result.returncode})
            
            return running
        except subprocess.TimeoutExpired:
            self.logger.log_event('WARN', 'healthcheck', 'browser.process.timeout')
            return False
    
    def check_browser_heartbeat(self, health_data: Optional[dict[str, Any]]) -> tuple[bool, Optional[int]]:
        """Check browser heartbeat from display_probe data.

        Args:
            health_data: Health endpoint response data

        Returns:
            Tuple of (heartbeat_ok, age_seconds)
        """
        if not health_data:
            return False, None

        display_probe = health_data.get('display_probe', {})
        last_heartbeat_iso = display_probe.get('last_render_probe_iso')

        if not last_heartbeat_iso:
            self.logger.log_event('WARN', 'healthcheck', 'browser.heartbeat.missing',
                                {'notes': 'No heartbeat timestamp in health data'})
            return False, None

        try:
            # Parse ISO timestamp
            from datetime import datetime, timezone
            heartbeat_time = datetime.fromisoformat(last_heartbeat_iso.replace('Z', '+00:00'))
            current_time = datetime.now(timezone.utc)
            age_seconds = int((current_time - heartbeat_time).total_seconds())

            # Check if heartbeat is stale
            timeout = self.health_config.get('browser_heartbeat_timeout_s', 120)
            heartbeat_ok = age_seconds <= timeout

            self.logger.log_event('DEBUG', 'healthcheck', 'browser.heartbeat.check',
                                {'age_s': age_seconds, 'timeout_s': timeout, 'ok': heartbeat_ok,
                                 'notes': display_probe.get('last_probe_notes')})

            return heartbeat_ok, age_seconds

        except (ValueError, TypeError) as e:
            self.logger.log_event('ERROR', 'healthcheck', 'browser.heartbeat.parse_error',
                                {'error': str(e), 'timestamp': last_heartbeat_iso})
            return False, None

    def check_x_server(self) -> bool:
        """Check if X server is responsive."""
        try:
            cmd = self.config.get('commands', {}).get('x_health_cmd', 'DISPLAY=:0 xdpyinfo >/dev/null 2>&1')
            result = subprocess.run(cmd, check=False, shell=True, timeout=5)

            running = result.returncode == 0
            self.logger.log_event('DEBUG', 'healthcheck', 'x.server.check',
                                {'running': running})
            
            return running
        except subprocess.TimeoutExpired:
            self.logger.log_event('WARN', 'healthcheck', 'x.server.timeout')
            return False


class RecoveryManager:
    """Escalating recovery actions with rate limiting."""
    
    def __init__(self, config: dict[str, Any], logger: StructuredLogger, state_mgr: WatchdogState):
        self.config = config
        self.logger = logger
        self.state_mgr = state_mgr
        self.commands = config.get('commands', {})
        self.thresholds = config.get('thresholds', {})
        self.recovery_config = config.get('recovery', {})
    
    def can_perform_action(self, action_type: str, state: dict[str, Any]) -> bool:
        """Check if action is within rate limits."""
        now = time.time()
        
        # Check cooldown from last recovery
        if state.get('last_recovery_time'):
            cooldown = self.thresholds.get('recovery_cooldown_s', 60)
            if now - state['last_recovery_time'] < cooldown:
                return False
        
        # Check specific action limits
        if action_type == 'browser_restart':
            max_per_hour = self.thresholds.get('max_browser_restarts_per_hour', 4)
            recent = [ts for ts in state.get('browser_restarts', []) if now - ts < 3600]
            return len(recent) < max_per_hour
        
        if action_type == 'service_restart':
            max_per_hour = self.thresholds.get('max_service_restarts_per_hour', 2)
            recent = [ts for ts in state.get('service_restarts', []) if now - ts < 3600]
            return len(recent) < max_per_hour
        
        if action_type == 'reboot':
            max_per_day = self.thresholds.get('max_reboots_per_day', 1)
            recent = [ts for ts in state.get('reboots', []) if now - ts < 86400]
            return len(recent) < max_per_day
        
        return True
    
    def perform_transient_retry(self, attempt: int) -> bool:
        """Level 0: Transient retry with exponential backoff."""
        intervals = self.recovery_config.get('retry_intervals', [10, 20, 40])
        if attempt >= len(intervals):
            return False

        wait_time = intervals[attempt]
        self.logger.log_event('INFO', 'recovery', 'transient.retry',
                            {'attempt': attempt + 1, 'wait_time_s': wait_time},
                            action_taken=True)

        time.sleep(wait_time)
        return True

    def reset_browser_escalation(self, state: dict[str, Any]) -> None:
        """Reset browser escalation level after successful recovery."""
        state['browser_escalation_level'] = 0
        state['browser_escalation_time'] = None
        self.state_mgr.save_state(state)
        self.logger.log_event('INFO', 'recovery', 'browser.escalation.reset')

    def soft_reload_browser(self, user: str, state: dict[str, Any]) -> bool:
        """Level 1: Soft browser reload using xdotool to send F5 key."""
        self.logger.log_event('INFO', 'recovery', 'browser.soft_reload.start', action_taken=True)

        try:
            # Use xdotool to send F5 key to browser window
            reload_cmd = self.recovery_config.get('browser_soft_reload', {}).get('reload_cmd',
                'DISPLAY=:0 xdotool search --class chromium windowactivate --sync key F5')

            result = subprocess.run(reload_cmd.format(user=user), check=False, shell=True,
                                  capture_output=True, timeout=10)

            if result.returncode == 0:
                # Wait for page to reload
                reload_delay = self.recovery_config.get('browser_soft_reload', {}).get('reload_delay_s', 15)
                time.sleep(reload_delay)

                state['last_recovery_time'] = time.time()
                self.state_mgr.save_state(state)

                self.logger.log_event('INFO', 'recovery', 'browser.soft_reload.complete')
                return True

            self.logger.log_event('WARN', 'recovery', 'browser.soft_reload.failed',
                                {'returncode': result.returncode,
                                 'stderr': result.stderr.decode('utf-8', errors='ignore')[:200]})
            return False

        except subprocess.TimeoutExpired:
            self.logger.log_event('ERROR', 'recovery', 'browser.soft_reload.timeout')
            return False
        except Exception as e:
            self.logger.log_event('ERROR', 'recovery', 'browser.soft_reload.error',
                                {'error': str(e)})
            return False

    def progressive_browser_recovery(self, user: str, state: dict[str, Any]) -> bool:
        """Progressive browser recovery with 3-level escalation.

        Level 1: Soft reload (F5 via xdotool)
        Level 2: Browser restart (kill and relaunch)
        Level 3: X session restart (kill X, triggers full restart)

        Args:
            user: Username for kiosk service
            state: Current watchdog state

        Returns:
            True if recovery action succeeded, False otherwise
        """
        # Get current escalation level
        level = state.get('browser_escalation_level', 0)

        self.logger.log_event('INFO', 'recovery', 'browser.progressive_recovery.start',
                            {'current_level': level})

        # Try recovery at current level
        success = False
        if level == 0:
            # Level 1: Soft reload
            success = self.soft_reload_browser(user, state)
        elif level == 1:
            # Level 2: Browser restart
            success = self.restart_browser(user, state)
        elif level == 2:
            # Level 3: X session restart
            success = self.restart_x_session(user, state)
        else:
            # Exceeded max level, escalate to service restart
            self.logger.log_event('ERROR', 'recovery', 'browser.progressive_recovery.max_exceeded',
                                {'level': level})
            return self.restart_service(user, state)

        # Update escalation state
        if success:
            # Record escalation attempt
            state['browser_escalation_level'] = level + 1
            state['browser_escalation_time'] = time.time()
            self.state_mgr.save_state(state)
            return True

        # If action failed, immediately escalate to next level
        self.logger.log_event('WARN', 'recovery', 'browser.progressive_recovery.failed_escalate',
                            {'failed_level': level, 'next_level': level + 1})
        state['browser_escalation_level'] = level + 1
        state['browser_escalation_time'] = time.time()
        self.state_mgr.save_state(state)
        return False

    def restart_browser(self, user: str, state: dict[str, Any]) -> bool:
        """Level 1: Restart browser process."""
        if not self.can_perform_action('browser_restart', state):
            self.logger.log_event('WARN', 'recovery', 'browser.restart.rate_limited')
            return False
        
        self.logger.log_event('INFO', 'recovery', 'browser.restart.start', action_taken=True)
        
        try:
            # Stop browser gracefully
            stop_cmd = self.commands.get('browser_stop_cmd', 'pkill -TERM chromium')
            subprocess.run(stop_cmd.format(user=user), check=False, shell=True, timeout=15)
            
            # Wait for browser restart verification delay
            restart_delay = self.recovery_config.get('browser_restart', {}).get('restart_verification_delay_s', 30)
            time.sleep(restart_delay)
            
            # Launch browser
            launch_cmd = self.commands.get('browser_launch_cmd', '')
            if launch_cmd:
                subprocess.Popen(launch_cmd.format(user=user), shell=True)
                
                # Update state
                state['browser_restarts'].append(time.time())
                state['last_recovery_time'] = time.time()
                self.state_mgr.save_state(state)
                
                self.logger.log_event('INFO', 'recovery', 'browser.restart.complete')
                return True
            self.logger.log_event('ERROR', 'recovery', 'browser.restart.no_command')
            return False
                
        except subprocess.TimeoutExpired:
            self.logger.log_event('ERROR', 'recovery', 'browser.restart.timeout')
            return False
        except Exception as e:
            self.logger.log_event('ERROR', 'recovery', 'browser.restart.error',
                                {'error': str(e)})
            return False
    
    def restart_x_session(self, user: str, state: dict[str, Any]) -> bool:
        """Level 3: Restart X session by killing X server.

        This kills the X server (Xorg), which causes startx to exit.
        The kiosk systemd service should detect this and restart the full stack:
        .bash_profile → startx → .xinitrc → browser
        """
        self.logger.log_event('INFO', 'recovery', 'x.restart.start', action_taken=True)

        try:
            restart_cmd = self.recovery_config.get('x_restart', {}).get('restart_cmd',
                'pkill -TERM Xorg || pkill -TERM X')

            subprocess.run(restart_cmd.format(user=user), check=False, shell=True, timeout=30)

            # Verification delay - X restart takes longer as service needs to restart full stack
            verify_delay = self.recovery_config.get('x_restart', {}).get('verification_delay_s', 60)
            time.sleep(verify_delay)

            state['last_recovery_time'] = time.time()
            self.state_mgr.save_state(state)

            self.logger.log_event('INFO', 'recovery', 'x.restart.complete')
            return True

        except subprocess.TimeoutExpired:
            self.logger.log_event('ERROR', 'recovery', 'x.restart.timeout')
            return False
        except Exception as e:
            self.logger.log_event('ERROR', 'recovery', 'x.restart.error',
                                {'error': str(e)})
            return False
    
    def restart_service(self, user: str, state: dict[str, Any]) -> bool:
        """Level 3: Restart systemd kiosk service."""
        if not self.can_perform_action('service_restart', state):
            self.logger.log_event('WARN', 'recovery', 'service.restart.rate_limited')
            return False
        
        self.logger.log_event('INFO', 'recovery', 'service.restart.start', action_taken=True)
        
        try:
            restart_cmd = self.commands.get('service_restart_cmd',
                'systemctl --user restart {kiosk_systemd_unit}')
            unit_name = self.commands.get('kiosk_systemd_unit', 'calendarbot-kiosk@{user}.service')
            
            full_cmd = restart_cmd.format(
                kiosk_systemd_unit=unit_name.format(user=user),
                user=user
            )
            
            subprocess.run(full_cmd, check=False, shell=True, timeout=60)
            
            # Verification delay
            verify_delay = self.recovery_config.get('service_restart', {}).get('verification_delay_s', 60)
            time.sleep(verify_delay)
            
            state['service_restarts'].append(time.time())
            state['last_recovery_time'] = time.time()
            self.state_mgr.save_state(state)
            
            self.logger.log_event('INFO', 'recovery', 'service.restart.complete')
            return True
            
        except subprocess.TimeoutExpired:
            self.logger.log_event('ERROR', 'recovery', 'service.restart.timeout')
            return False
        except Exception as e:
            self.logger.log_event('ERROR', 'recovery', 'service.restart.error',
                                {'error': str(e)})
            return False
    
    def reboot_system(self, state: dict[str, Any]) -> bool:
        """Level 4: System reboot (last resort)."""
        if not self.can_perform_action('reboot', state):
            self.logger.log_event('WARN', 'recovery', 'reboot.rate_limited')
            return False
        
        self.logger.log_event('ERROR', 'recovery', 'reboot.start',
                            {'reason': 'escalated_recovery'}, action_taken=True)
        
        try:
            # Update state before reboot
            state['reboots'].append(time.time())
            state['last_recovery_time'] = time.time()
            self.state_mgr.save_state(state)
            
            # Delay for log shipping
            reboot_delay = self.recovery_config.get('reboot', {}).get('reboot_delay_s', 30)
            time.sleep(reboot_delay)
            
            # Initiate reboot
            reboot_cmd = self.recovery_config.get('reboot', {}).get('reboot_cmd', 'sudo /sbin/reboot')
            subprocess.run(reboot_cmd, check=False, shell=True, timeout=10)
            
            return True
            
        except Exception as e:
            self.logger.log_event('ERROR', 'recovery', 'reboot.error',
                                {'error': str(e)})
            return False


def load_config(config_path: Path) -> dict[str, Any]:
    """Load YAML configuration with environment variable overrides."""
    try:
        import yaml
    except ImportError:
        print("PyYAML is required but not installed. Install with: pip install PyYAML")
        sys.exit(1)
    
    try:
        with open(config_path) as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"Failed to load config from {config_path}: {e}")
        sys.exit(1)
    
    # Environment variable overrides
    monitor_config = config.get('monitor', {})
    
    if os.environ.get('CALENDARBOT_WATCHDOG_LOG_LEVEL'):
        monitor_config.setdefault('logging', {})['log_level'] = os.environ['CALENDARBOT_WATCHDOG_LOG_LEVEL']
    
    if os.environ.get('CALENDARBOT_WATCHDOG_DEBUG') == 'true':
        monitor_config.setdefault('logging', {})['log_level'] = 'DEBUG'
    
    if os.environ.get('CALENDARBOT_WATCHDOG_DEGRADED') == 'true':
        monitor_config['degraded_mode'] = True
    
    if os.environ.get('CALENDARBOT_WATCHDOG_DISABLED') == 'true':
        monitor_config['disabled'] = True
    
    return monitor_config


def setup_logging(config: dict[str, Any]) -> tuple[logging.Logger, StructuredLogger]:
    """Setup logging with rotation and journald integration."""
    log_config = config.get('logging', {})
    log_level = getattr(logging, log_config.get('log_level', 'INFO').upper())
    
    # Create logger
    logger = logging.getLogger('calendarbot-watchdog')
    logger.setLevel(log_level)
    
    # Console handler for systemd/journald
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(log_level)
    
    if log_config.get('json_logging', True):
        console_handler.setFormatter(logging.Formatter('%(message)s'))
    else:
        console_handler.setFormatter(
            logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        )
    
    logger.addHandler(console_handler)
    
    # Local file handler with rotation
    log_dir = Path(log_config.get('local_log_dir', '/var/log/calendarbot-watchdog'))
    if log_dir.exists() or log_dir.mkdir(parents=True, exist_ok=True):
        try:
            from logging.handlers import RotatingFileHandler
            
            max_size = log_config.get('max_log_size_mb', 2) * 1024 * 1024
            backup_count = log_config.get('log_files_to_keep', 7)
            
            file_handler = RotatingFileHandler(
                log_dir / 'watchdog.log',
                maxBytes=max_size,
                backupCount=backup_count
            )
            file_handler.setLevel(log_level)
            file_handler.setFormatter(
                logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            )
            logger.addHandler(file_handler)
        except Exception as e:
            logger.warning(f"Failed to setup file logging: {e}")
    
    return logger, StructuredLogger(logger)


def signal_handler(signum: int, _frame) -> None:
    """Handle shutdown signals gracefully."""
    global _shutdown_requested
    _shutdown_requested = True
    print(f"Received signal {signum}, shutting down gracefully...")


def main() -> int:
    """Main watchdog loop."""
    global _config, _shutdown_requested
    
    parser = argparse.ArgumentParser(description='CalendarBot Kiosk Watchdog')
    parser.add_argument('--config', type=Path, required=True,
                       help='Path to monitor.yaml configuration file')
    parser.add_argument('--user', type=str, required=True,
                       help='Kiosk user name')
    parser.add_argument('--version', action='version', version=f'%(prog)s {__version__}')
    
    args = parser.parse_args()
    
    # Load configuration
    _config = load_config(args.config)
    
    # Check if disabled
    if _config.get('disabled', False):
        print("Watchdog disabled by configuration")
        return 0
    
    # Setup logging
    _logger, structured_logger = setup_logging(_config)
    
    # Setup signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # Initialize components
    state_mgr = WatchdogState(_config.get('state', {}).get('state_file',
                             '/var/local/calendarbot-watchdog/state.json'))
    health_checker = HealthChecker(_config, structured_logger)
    recovery_mgr = RecoveryManager(_config, structured_logger, state_mgr)
    
    structured_logger.log_event('INFO', 'watchdog', 'service.start',
                              {'version': __version__, 'user': args.user})
    
    # Main monitoring loop
    consecutive_failures = 0
    last_health_check = 0
    last_render_check = 0
    last_x_check = 0
    last_heartbeat_check = 0
    render_failures = 0
    heartbeat_failures = 0
    
    while not _shutdown_requested:
        try:
            current_time = time.time()
            state = state_mgr.load_state()
            state_mgr.cleanup_old_entries(state)
            
            # Check for degraded mode
            degraded = _config.get('degraded_mode', False) or SystemDiagnostics.should_degrade(_config)
            if degraded:
                structured_logger.log_event('WARN', 'watchdog', 'degraded.mode.active')
            
            # Determine check intervals (double if degraded)
            health_interval = _config.get('health_check', {}).get('interval_s', 30)
            render_interval = _config.get('health_check', {}).get('render_probe_interval_s', 60)
            x_interval = _config.get('health_check', {}).get('x_health_interval_s', 120)
            
            if degraded:
                factor = _config.get('resource_limits', {}).get('degradation_factor', 2.0)
                health_interval *= factor
                render_interval *= factor
                x_interval *= factor
            
            # Health endpoint check
            if current_time - last_health_check >= health_interval:
                health_ok, _health_data = health_checker.check_health_endpoint()
                last_health_check = current_time
                
                if not health_ok:
                    consecutive_failures += 1
                    structured_logger.log_event('WARN', 'watchdog', 'health.check.fail',
                                              {'consecutive_failures': consecutive_failures})
                    
                    # Start recovery escalation
                    max_retries = _config.get('health_check', {}).get('max_retries', 3)
                    
                    if consecutive_failures <= max_retries:
                        # Level 0: Transient retry
                        recovery_mgr.perform_transient_retry(consecutive_failures - 1)
                    elif consecutive_failures <= max_retries + 2:
                        # Level 1: Browser restart
                        if recovery_mgr.restart_browser(args.user, state):
                            consecutive_failures = 0
                    elif consecutive_failures <= max_retries + 4:
                        # Level 2: X restart
                        if recovery_mgr.restart_x_session(args.user, state):
                            consecutive_failures = 0
                    elif consecutive_failures <= max_retries + 6:
                        # Level 3: Service restart
                        if recovery_mgr.restart_service(args.user, state):
                            consecutive_failures = 0
                    else:
                        # Level 4: Reboot
                        recovery_mgr.reboot_system(state)
                        break
                else:
                    consecutive_failures = 0
                    render_failures = 0

                    # Browser heartbeat check (when health is ok)
                    heartbeat_interval = _config.get('health_check', {}).get('browser_heartbeat_check_interval_s', 60)
                    if current_time - last_heartbeat_check >= heartbeat_interval:
                        heartbeat_ok, age_s = health_checker.check_browser_heartbeat(_health_data)
                        last_heartbeat_check = current_time

                        if not heartbeat_ok:
                            heartbeat_failures += 1
                            structured_logger.log_event('WARN', 'watchdog', 'browser.heartbeat.stale',
                                                      {'heartbeat_failures': heartbeat_failures,
                                                       'age_s': age_s,
                                                       'escalation_level': state.get('browser_escalation_level', 0)})

                            # Escalate after threshold
                            fail_threshold = _config.get('thresholds', {}).get('browser_heartbeat_fail_count', 2)
                            if heartbeat_failures >= fail_threshold:
                                structured_logger.log_event('ERROR', 'watchdog', 'browser.heartbeat.escalate',
                                                          {'heartbeat_failures': heartbeat_failures,
                                                           'threshold': fail_threshold,
                                                           'escalation_level': state.get('browser_escalation_level', 0)})
                                # Use progressive recovery instead of direct browser restart
                                if recovery_mgr.progressive_browser_recovery(args.user, state):
                                    heartbeat_failures = 0
                                    # Don't reset escalation yet - wait for heartbeat to be OK
                        else:
                            # Heartbeat is OK - reset failures and escalation
                            if heartbeat_failures > 0 or state.get('browser_escalation_level', 0) > 0:
                                structured_logger.log_event('INFO', 'watchdog', 'browser.heartbeat.recovered',
                                                          {'previous_failures': heartbeat_failures,
                                                           'previous_escalation': state.get('browser_escalation_level', 0)})
                            heartbeat_failures = 0
                            recovery_mgr.reset_browser_escalation(state)

            # Render probe check
            if current_time - last_render_check >= render_interval:
                render_ok = health_checker.check_render_probe()
                last_render_check = current_time
                
                if not render_ok:
                    render_failures += 1
                    if render_failures >= _config.get('thresholds', {}).get('render_fail_count', 2):
                        structured_logger.log_event('WARN', 'watchdog', 'render.probe.escalate',
                                                  {'render_failures': render_failures})
                        if recovery_mgr.restart_browser(args.user, state):
                            render_failures = 0
                else:
                    render_failures = 0
            
            # X server check
            if current_time - last_x_check >= x_interval:
                x_ok = health_checker.check_x_server()
                last_x_check = current_time
                
                if not x_ok:
                    structured_logger.log_event('WARN', 'watchdog', 'x.server.fail')
                    recovery_mgr.restart_x_session(args.user, state)
            
            # Browser process check
            if not health_checker.check_browser_process():
                structured_logger.log_event('WARN', 'watchdog', 'browser.process.missing')
                recovery_mgr.restart_browser(args.user, state)
            
            # Sleep until next check
            time.sleep(min(health_interval, render_interval, x_interval, 30))
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            structured_logger.log_event('ERROR', 'watchdog', 'main.loop.error',
                                      {'error': str(e)})
            time.sleep(10)  # Brief pause on error
    
    structured_logger.log_event('INFO', 'watchdog', 'service.stop')
    return 0


if __name__ == '__main__':
    sys.exit(main())
